{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **Riiid! Answer Correctness Prediction**"},{"metadata":{},"cell_type":"markdown","source":"## Imports librairies"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport time\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.metrics import roc_auc_score\nfrom tqdm.notebook import tqdm\n\n\n\n#del datafram_df\n#gc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_filling_rate (data_df, a_label_abscisse, color_graphe, color_threshold  ) : \n    \"\"\" \n        Display the filling rate of the columns\n        @donnees_df : dataframe qui contient les données\n        @a_seuil : booléen égal à True si on souhaite afficher le seuil\n        @a_label_abscisse : booléen égal à True si on souhaite afficher le nom des colonnes en abscisse\n        @color_graphe\n        @color_threshold \n    \"\"\"\n    if(color_graphe == ''):\n        color_graphe = 'blue'\n    data = (data_df.count() / len(data_df)).sort_values().values\n    ind = np.arange(len(data))\n    width = 0.5\n    fig, axes = plt.subplots(1,1,figsize=(6, 3), dpi=100)\n    tr = axes.bar(ind, data, width, color=color_graphe)\n    axes.set_ylabel('Filling rates');\n    if(a_label_abscisse):\n        axes.set_xticks(ind )\n        axes.set_xticklabels((data_df.count() / len(data_df)).sort_values().index, fontsize=10, rotation=90)\n        axes.legend([tr], ['Filling rates'])\n        \n\ndef print_pie(data_df, column, title_fig, title_legend) :\n    \"\"\"\n    @data_df : data\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(6, 6))\n    #colors = ['blue','orange', 'green',  'pink', 'blue', 'teal',  'olive',    'deepskyblue',  'slategray',  'rebeccapurple',   'rosybrown','indianred','goldenrod','gold', 'khaki']\n    ttl = plt.title(title_fig, fontsize=15, weight=\"bold\")\n    ttl.set_position([0, 1.05])\n    data_df[column].value_counts(normalize=True).sort_index().plot(kind='pie', startangle=180, counterclock = False, autopct='%1.1f%%', fontsize = 14) #labels =labels, \n    plt.axis('equal')\n    plt.ylabel('')\n    plt.rcParams['legend.title_fontsize'] = 'large'\n    ax.legend(title=title_legend, loc=\"center right\",  bbox_to_anchor=(1, 0, 1, 1), fontsize='medium') #labels,\n    plt.show()\n        \n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data loading\n\nWe will follow this tutorials : [Competition API Detailed Introduction](https://www.kaggle.com/sohier/competition-api-detailed-introduction) and \n[Tutorial on reading large datasets](http://https://www.kaggle.com/rohanrao/tutorial-on-reading-large-datasets/)."},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nquestions_df = pd.read_csv('/kaggle/input/riiid-test-answer-prediction/questions.csv')\nlectures_df = pd.read_csv('/kaggle/input/riiid-test-answer-prediction/lectures.csv')\nexample_test = pd.read_csv('/kaggle/input/riiid-test-answer-prediction/example_test.csv')\nexample_sample_submission = pd.read_csv('/kaggle/input/riiid-test-answer-prediction/example_sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <span style=\"color:green\">train.csv<span style=\"color:darkblue\">\n### <span style=\"color:green\">The variables :<span style=\"color:darkblue\"> \n\n**<span style=\"color:darkblue\">row_id</span>**: (int64) ID code for the row.\n\n<span style=\"color:darkblue\">**user_id**</span>: (int32) ID code for the user.\n    \n<span style=\"color:darkblue\">**timestamp**</span>: (int64) the time in milliseconds between this user interaction and the first event completion from that user. <br>\n<span style=\"color:crimson\">**Continuous variable**</span>\n\n    \n<span style=\"color:darkblue\">**user_answer**</span>: (int8) <br />\n0, 1, 2, 3 if content_type_id == 0. -1 if content_type_id <br>\n<span style=\"color:crimson\">**Categorical variable**</span>\n\n\n<span style=\"color:darkblue\">**content_id**</span>: (int16) ID code for the user interaction\n\n    \n<span style=\"color:darkblue\">**content_type_id**</span>: (int8) 0 if the event was a question being posed to the user, 1 if the event was the user watching a lecture.<br>\n<span style=\"color:crimson\">**Categorical variable**</span>\n\n<span style=\"color:darkblue\">**task_container_id**</span>: (int16) Id code for the batch of questions or lectures. For example, a user might see three questions in a row before seeing the explanations for any of them. Those three would all share a task_container_id.\n\n<span style=\"color:darkblue\">**prior_question_elapsed_time**</span>: (float32) The average time in milliseconds it took a user to answer each question in the previous question bundle, ignoring any lectures in between. Is null for a user's first question bundle or lecture. Note that the time is the average time a user took to solve each question in the previous bundle.<br>\n<span style=\"color:crimson\">**Continuous variable**</span>\n\n<span style=\"color:darkblue\">**prior_question_had_explanation**</span>: (bool) Whether or not the user saw an explanation and the correct response(s) after answering the previous question bundle, ignoring any lectures in between. The value is shared across a single question bundle, and is null for a user's first question bundle or lecture. Typically the first several questions a user sees were part of an onboarding diagnostic test where they did not get any feedback.<br>\n<span style=\"color:crimson\">**Boolean variable**</span>\n\n<span style=\"color:green\">**TARGET**:</span><br>\n\n<span style=\"color:darkblue\">**answered_correctly**</span>: (int8) if the user responded correctly. Read -1 as null, for lectures.<br>\n\n\n\n=> We want to predict if the user will answer correctly or not.<br>\nWe will exclure the value \"-1\" which corresponds to the lecture, not the answer.<br>\n<span style=\"color:magenta\">**So we have a binary classification problem to solve.**</span>"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\ndtypes = {\n    \"row_id\": \"int64\",\n    \"timestamp\": \"int64\",\n    \"user_id\": \"int32\",\n    \"content_id\": \"int16\",\n    \"content_type_id\": \"int8\",\n    \"task_container_id\": \"int16\",\n    \"user_answer\": \"int8\",\n    \"answered_correctly\": \"int8\",\n    \"prior_question_elapsed_time\": \"float32\", \n    \"prior_question_had_explanation\": \"boolean\"\n}\n\ntrain_df = pd.read_csv('/kaggle/input/riiid-test-answer-prediction/train.csv', \n                       low_memory=False, \n                       nrows=10**6, \n                       dtype=dtypes\n                      )\nprint(\"Train size:\", train_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.memory_usage(deep=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"train_df.head(4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The dataset contains {} rows and {} columns. \\n\".format(train_df.shape[0], train_df.shape[0]))\nfor col in train_df:\n    print(\"The column {} has {} unique values.\".format(col, train_df[col].nunique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_df.isnull().sum())\nprint(\"****************************************\")\nprint(train_df.isnull().sum() / len(train_df))\n\nprint_filling_rate (train_df, True, \"blue\", \"blue\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## user_id\n\n* 3 824 unique users\n* no missing value"},{"metadata":{},"cell_type":"markdown","source":"## Categorical variables :\n* content_type_id\n* user_answer\n* answered_correctly **(TARGET)**"},{"metadata":{},"cell_type":"markdown","source":"### content_type_id"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df.content_type_id.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(5, 5))\nplt.title('Percentage of content type : questions or lectures', fontsize=15, weight=\"bold\")\nlabels = ['Questions','Lectures']\ncolors = ['lightgray','peachpuff']\nexplode=(0.1,0.2 )\ntrain_df[\"content_type_id\"].value_counts(normalize=True).plot(kind='pie', labels=labels, colors=colors, explode=explode, startangle=50, autopct='%1.1f%%', fontsize = 13)\nplt.axis('equal') \nplt.ylabel('')\nplt.show()\n\nprint(train_df['content_type_id'].value_counts().sort_index().to_frame())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The majority of the users interactions is <span style=\"color:magenta\">**questions**</span> : 98% VS 2% for lectures."},{"metadata":{},"cell_type":"markdown","source":"### user_answer"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.user_answer.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"print_pie(train_df[train_df['user_answer']>=0], 'user_answer', \"Percentage of user answers (only questions) :\", \"User answers: \")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The user answers are 0, 1, 2 or 3. But what means 0 : is it a possible answer, or does it mean \"no answer\" ? \nLet have a look at the possible answers (in questions_df) :"},{"metadata":{"trusted":true},"cell_type":"code","source":"print_pie(questions_df, 'correct_answer', \"Percentage of possible answers:\", \"Possible answers: \")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ok, 0 is a possible answer. \n\nHow to know if the user didn't know the answer, is it something possible ?"},{"metadata":{},"cell_type":"markdown","source":"## **answered_correctly = TARGET**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.answered_correctly.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print_pie(train_df[train_df['answered_correctly']>=0], 'answered_correctly', \"User answered correctly ? :\", \"Answered correctly : \")\nfig, ax = plt.subplots(figsize=(5, 5))\nplt.title('Percentage of correct and uncorrect answers (only questions) :', fontsize=15, weight=\"bold\")\nlabels = ['Correct', 'Uncorrect']\ncolors = ['lightgray','peachpuff']\nexplode=(0.1,0)\ntrain_df[train_df['answered_correctly']>=0][\"answered_correctly\"].value_counts(normalize=True).plot(kind='pie', labels=labels, colors=colors, explode=explode, startangle=50, autopct='%1.1f%%', fontsize = 13)\nplt.axis('equal') \nplt.ylabel('')\nplt.show()\n\nprint(train_df[train_df['answered_correctly']>=0]['answered_correctly'].value_counts().sort_index().to_frame())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 'prior_question_had_explanation' (boolean)"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['prior_question_had_explanation'].fillna(False, inplace=True)\ntrain_df.loc[train_df[\"prior_question_had_explanation\"]== True, \"prior_had_explanation_le\"] = 1\ntrain_df.loc[train_df[\"prior_question_had_explanation\"]== False, \"prior_had_explanation_le\"] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print_pie(train_df[train_df['answered_correctly']>=0], 'answered_correctly', \"User answered correctly ? :\", \"Answered correctly : \")\nfig, ax = plt.subplots(figsize=(5, 5))\nplt.title('Prior question had explanation ? (percentage):', fontsize=15, weight=\"bold\")\nlabels = ['Yes', 'No']\ncolors = ['lightgray','peachpuff']\nexplode=(0.1,0)\ntrain_df[\"prior_had_explanation_le\"].value_counts(normalize=True).plot(kind='pie', labels=labels, colors=colors, explode=explode, startangle=50, autopct='%1.1f%%', fontsize = 13)\nplt.axis('equal') \nplt.ylabel('')\nplt.show()\n\nprint(train_df['prior_had_explanation_le'].value_counts().sort_index().to_frame())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_columns', None)\npivot_table = pd.pivot_table(train_df, index=['user_answer']).style.background_gradient()\npivot_table","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_only_questions_df = train_df[train_df['content_type_id'] == 0]\ntrain_only_questions_df['prior_question_had_explanation'].value_counts() / len(train_only_questions_df[~train_only_questions_df['prior_question_had_explanation'].isna()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_only_questions_df[~train_only_questions_df['prior_question_had_explanation'].isna()].groupby('prior_question_had_explanation')['answered_correctly'].mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Continue variables :\n* timestamp (Time variables milliseconds)\n* prior_question_elapsed_time (Time variables milliseconds)"},{"metadata":{},"cell_type":"markdown","source":"### timestamp"},{"metadata":{"trusted":true},"cell_type":"code","source":"nbMillisecByYear = 1000 * 60 * 60 * 24 * 365\nnbMillisecByMonth = nbMillisecByYear / 12\ntrain_df['timestamp_by_month'] = train_df['timestamp']/nbMillisecByMonth\nfig = plt.figure(figsize=(12,6))\ntrain_df['timestamp_by_month'].plot.hist(bins=100)\nplt.title(\"Histogram of timestamp converted in month\")\nplt.xticks(rotation=0)\nplt.xlabel(\"Months between this user interaction and the first event completion from that user\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df[train_df['timestamp_by_month'] <= 24]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['timestamp'].plot(kind='box', subplots=True, title='Boxplot timestamp', figsize=(20,20), layout=(4,4))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### prior_question_elapsed_time"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['prior_question_elapsed_time'].hist(figsize=(7,4), density=True, bins= 50)\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"time_limit = 5*60*1000\nprint(time_limit)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['prior_question_elapsed_time_in_min'] = train_df['prior_question_elapsed_time']/1000/60","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['prior_question_elapsed_time'].plot(kind='box', subplots=True, title='Boxplot prior_question_elapsed_time', figsize=(20,20), layout=(4,4))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prior_question_elapsed_time_mean = train_df[~train_df['prior_question_elapsed_time'].isna()]['prior_question_elapsed_time'].mean()\ntrain_df['prior_question_elapsed_time'].fillna(prior_question_elapsed_time_mean, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Correlation"},{"metadata":{"trusted":true},"cell_type":"code","source":"list_columns_corr = ['timestamp', 'user_id', 'content_id', \n                     'task_container_id', 'user_answer', 'answered_correctly',\n                     'prior_question_elapsed_time', 'prior_question_had_explanation']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = train_df[~(train_df['prior_question_elapsed_time'].isna())][list_columns_corr].corr(method = \"kendall\")\nf, ax = plt.subplots(figsize=(10, 10))\nplt.rcParams['font.size'] = 11\nax.set_title('Kendall correlation')\n\n#A1 = ['Calories','Mat. grasse','M.G.saturée','Glucides','Sucre','Fibres','Protéines','Sel','Sodium']\n\nsns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), fmt=\".2f\", cmap='coolwarm', square=True, ax=ax ) #, xticklabels=A1, yticklabels=A1 )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## questions.csv"},{"metadata":{"trusted":true},"cell_type":"code","source":"questions_df[questions_df['tags'].isna()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"questions_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"questions_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(questions_df.isnull().sum())\nprint(\"****************************************\")\nprint(questions_df.isnull().sum() / len(train_df))\n\nprint_filling_rate (questions_df, True, \"green\", \"green\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"questions_df['tags'].fillna(\"\", inplace=True)\nquestions_df[\"nb_tags\"] = questions_df[\"tags\"].apply(lambda text: len(text.split()))\n\nquestions_df[questions_df['question_id'] == 10033]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"questions_df = questions_df[questions_df[\"nb_tags\"] > 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = \"\".split()\nlen(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Le nombre max de tags par question : {}'.format(max(questions_df['nb_tags'])))\nprint('Le nombre min de tag par question : {}'.format(min(questions_df['nb_tags'])))\nprint('Le nombre moyen de tags par question : %f'%(sum(questions_df['nb_tags'])/len(questions_df['nb_tags'])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.style as style\nstyle.use('seaborn-dark-palette')\nfig, ax = plt.subplots(figsize=(10, 5))\nax.set_title(\"Répartition du nombre de tags par question\", fontsize=16, weight=\"bold\");\n\nsns.countplot(questions_df['nb_tags'], palette=\"Set1\")\nax.set_ylabel(\"Nombre d'occurences\", fontsize=14)\nax.set_xlabel(\"Nombre de tags par question\", fontsize=14);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tag = questions_df[\"tags\"].str.split(\" \", n = 10, expand = True) \ntag.columns = ['tags1','tags2','tags3','tags4','tags5','tags6']\n\nquestions_df =  pd.concat([questions_df,tag],axis=1)\nquestions_df['tags1'] = pd.to_numeric(questions_df['tags1'], errors='coerce')\nquestions_df['tags2'] = pd.to_numeric(questions_df['tags2'], errors='coerce')\nquestions_df['tags3'] = pd.to_numeric(questions_df['tags3'], errors='coerce')\nquestions_df['tags4'] = pd.to_numeric(questions_df['tags4'], errors='coerce')\nquestions_df['tags5'] = pd.to_numeric(questions_df['tags5'], errors='coerce')\nquestions_df['tags6'] = pd.to_numeric(questions_df['tags6'], errors='coerce')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"questions_df['tags_list'] = questions_df['tags'].apply(lambda x: x.split())\ntags_list = [item for sublist in questions_df['tags_list'].values for item in sublist]\nprint(len(tags_list))\ntags_unique_list = list(set(tags_list))\n# Affiche la nouvelle liste \nprint(len(tags_unique_list))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\ndef distribution_nb_apparition_tag_questions(nb_tags, title, with_return):\n    tags_most_common = tags_frequence.most_common(nb_tags)\n    tags_df = pd.DataFrame(tags_most_common, columns = ['tags' , 'nb_tags']) \n    tags_df.columns\n    tags_sorted_df = tags_df.sort_values(['nb_tags'], ascending=False)\n    tags_counts = tags_sorted_df['nb_tags'].values\n    plt.plot(tags_counts)\n    plt.title(title)\n    plt.grid()\n    plt.xlabel(\"Nombre de tags\")\n    plt.ylabel(\"Nombre d'occurences\")\n    plt.show()\n    if(with_return):\n        return tags_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tags_frequence= nltk.FreqDist(tags_list)\n\n\n\ntags_df = distribution_nb_apparition_tag_questions(len(tags_unique_list), \"Distribution du nombre d'apparition des tags\", True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"distribution_nb_apparition_tag_questions(25, \"Distribution du nombre d'apparition des 25 tags les plus fréquents\", False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NB_TAGS = 25\ndistribution_nb_apparition_tag_questions(NB_TAGS, \"Distribution du nombre d'apparition des NB_TAGS tags les plus fréquents\", False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"words_most_common = tags_frequence.most_common(NB_TAGS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fq_words_df = pd.DataFrame(words_most_common, columns = ['tags' , 'nb_tags']) \nfq_words_df.head()\nSELECTED_TAGS = (fq_words_df['tags'][:NB_TAGS]).to_list()\nprint(SELECTED_TAGS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tags_column_processing(tags):\n    new_tags = []\n    tags_words = tags.split()\n    for tag in tags_words:\n        if (tag in SELECTED_TAGS) :\n            new_tags.append(tag)   \n    return new_tags\n\nquestions_df['new_tags'] = questions_df[\"tags\"].apply(lambda text : tags_column_processing(text))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MultiLabelBinarizer\nclasses_tags = tuple(SELECTED_TAGS)\none_hot = MultiLabelBinarizer(classes = classes_tags )\n#print(one_hot.fit_transform(questions_df['new_tags']))\n\n#print(one_hot.classes_)\n\n\ntypes_encoded = pd.DataFrame(one_hot.fit_transform(questions_df['new_tags']),columns=one_hot.classes_)\ntypes_encoded.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Concating df and types_encoded\nquestions_df = pd.concat([questions_df,types_encoded], axis = 1)\nquestions_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"questions_df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop column B as it is now encoded\nquestions_df = questions_df.drop(['new_tags', 'tags', 'tags_list'],axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"questions_df = questions_df[~questions_df['part'].isna()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"questions_df['part'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"questions_df['is_reading_section']= 0 \nquestions_df.loc[questions_df['part'] >= 5 ,'is_reading_section'] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"questions_df['is_easy_part'] = 0\nquestions_df['is_medium_part'] = 0\nquestions_df['is_difficult_part'] = 0\nquestions_df.loc[questions_df['part'] <= 3 ,'is_easy_part'] = 1\nquestions_df.loc[(questions_df['part'] == 4)|(questions_df['part'] == 5) ,'is_difficult_part'] = 1\nquestions_df.loc[questions_df['part'] >6 ,'is_medium_part'] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"questions_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"questions_df.head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Lectures.csv\ncf https://www.kaggle.com/jsylas/utilize-lecture-in-your-model-before-answering"},{"metadata":{"trusted":true},"cell_type":"code","source":"lecture_cnt = train_df[train_df.content_type_id == True][['user_id','content_type_id']].groupby(['user_id'],as_index = False).agg(['sum']).reset_index()\nlecture_cnt.columns = [\"user_id\",\"lecture_heard_count\"]\nuser_list = lecture_cnt['user_id'].unique()\ntrain = train_df[train_df.content_type_id == False]\ntrain_lecture_not_heard = train[~train.user_id.isin(user_list)]\ntrain_lecture_heard = train[train.user_id.isin(user_list)]\ntrain_lecture_not_heard_unq = pd.DataFrame(train_lecture_not_heard['user_id'].unique())\ntrain_lecture_not_heard_unq.columns = ['user_id']\ntrain_lecture_not_heard_unq['lecture'] = 'Not Heard'\ntrain_lecture_heard_unq = pd.DataFrame(train_lecture_heard['user_id'].unique())\ntrain_lecture_heard_unq.columns = ['user_id']\ntrain_lecture_heard_unq['lecture'] = 'Heard'\ntrain_lecture = pd.concat([train_lecture_not_heard_unq,train_lecture_heard_unq],axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualizing Lecture Heard Student VS Lecture Not Heard Student\nplt.figure(figsize=(10,5))\nax = sns.countplot(x=train_lecture['lecture'], palette=['#f76f6f',\"#0cdeed\"])\nax.set_xlabel('Lecture Heard Student VS Lecture Not Heard Student',size=15)\nplt.title(\"Number of Student : 393656\",size=15)\n\nfor p in ax.patches:\n    x=p.get_bbox().get_points()[:,0]\n    y=p.get_bbox().get_points()[1,1]\n    ax.annotate('{:.0f}'.format(p.get_height()), (x.mean(), y), ha='center', va='bottom')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_lecture_not_heard_mean = train_lecture_not_heard[['user_id','answered_correctly']].groupby(['user_id'],as_index = False).agg(['mean']).reset_index()\ntrain_lecture_not_heard_mean.columns= ['user_id','train_lecture_not_heard_mean']\ntrain_lecture_heard_mean = train_lecture_heard[['user_id','answered_correctly']].groupby(['user_id'],as_index = False).agg(['mean']).reset_index()\ntrain_lecture_heard_mean.columns = ['user_id','train_lecture_heard_mean']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams['figure.figsize'] = [15,10]\nplt.rcParams['font.size'] = 14\nsns.kdeplot(train_lecture_heard_mean.train_lecture_heard_mean, label=\"Lecture Heard\", clip=[0,1])\nplt.axvline(train_lecture_heard['answered_correctly'].mean(), color='blue')\nsns.kdeplot(train_lecture_not_heard_mean.train_lecture_not_heard_mean, label=\"Lecture Not Heard\", clip=[0,1])\nplt.axvline(train_lecture_not_heard['answered_correctly'].mean(), color='orange')\n\n# add text \nplt.text(train_lecture_heard_mean.train_lecture_heard_mean.mean()-.3, 3,\n         f\"Lecture Heard Student Mean  mean={round(train_lecture_heard['answered_correctly'].mean(), 2)}\")\n\nplt.text(train_lecture_not_heard_mean.train_lecture_not_heard_mean.mean()-.25, 2.5,\n         f\"Lecture Not Heard Student Mean mean={round(train_lecture_not_heard['answered_correctly'].mean(), 2)}\")\n\nplt.title(\"Lecture Heard Vs Lecture Not Heard\")\nplt.xlabel(\"average answer correctness per user\")\nplt.ylabel(\"pdf\")\n\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see in this analysis, the students who had lecture before answering performe better than the students whithout."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_lecture.groupby('user_id').count)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Merge questions and train"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.merge(train_df,questions_df, how='left', left_on='content_id', right_on='question_id').sort_values('row_id')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()\n#train_df[train_df['1'] == 1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pivot tables"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[['user_answer', 'answered_correctly']].groupby(['user_answer'], as_index=False).mean().sort_values(by='answered_correctly', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[['part', 'answered_correctly']].groupby(['part'], as_index=False).mean().sort_values(by='answered_correctly', ascending=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display information by user ID \nprint(pd.pivot_table(train_df, index='user_id', values=['timestamp', 'prior_question_elapsed_time', 'answered_correctly'], aggfunc='mean'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Target"},{"metadata":{"trusted":true},"cell_type":"code","source":"(train_df['answered_correctly']==-1).mean()\n# We should exclude information about lectures.\ntrain_df_questions = train_df[train_df['answered_correctly']!=-1]\ntrain_df_questions['answered_correctly'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''cids = train_df.content_id.value_counts()[:30]\n\nfig = plt.figure(figsize=(12,6))\nax = cids.plot.bar()\nplt.title(\"Thirty most used content id's\")\nplt.xticks(rotation=90)\nax.get_yaxis().set_major_formatter(FuncFormatter(lambda x, p: format(int(x), ','))) #add thousands separator\nplt.show()'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['is_first_question'] = 0\n\ntrain_df.loc[train_df['prior_question_elapsed_time'].isna(),'is_first_question'] = 1\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"user_agg = train_df.groupby('user_id')['answered_correctly'].\\\n                    agg(['sum', 'count']) #,'mean','median','std'])\n#train_df['user_sum'] = train_df['user_id'].map(user_agg['sum']).astype('int32')\ntrain_df['user_count'] = train_df['user_id'].map(user_agg['count']).astype('int32')\ntrain_df['user_nb_mean'] = train_df['user_id'].map(user_agg['sum']/user_agg['count']).astype('int32')\n#train_df['user_mean'] = train_df['user_id'].map(user_agg['mean']).astype('int32')\n#train_df['user_median'] = train_df['user_id'].map(user_agg['median']).astype('int32')\n#train_df['user_std'] = train_df['user_id'].map(user_agg['std']).astype('int32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['part'].fillna(4, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"content_agg = train_df.groupby('content_id')['answered_correctly'].\\\n                        agg(['sum', 'count']) #'mean', 'median', 'std'\ntrain_df['content_count'] = train_df['content_id'].map(content_agg['count']).astype('int32')\n#train_df['content_sum'] = train_df['content_id'].map(content_agg['sum']).astype('int32')\ntrain_df['content_nb_mean'] = train_df['content_id'].map(content_agg['sum'] / content_agg['count'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Baseline"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.columns\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df[train_df['answered_correctly']!= -1]\n\nfeatures_bsl = ['timestamp_by_month', 'tags1', 'tags2', 'tags3', \n                'tags4', 'tags5', 'tags6', \n                'is_first_question', 'part',\n                'prior_had_explanation_le', \n                'prior_question_elapsed_time_in_min',\n                'content_id', 'content_count', 'content_nb_mean',\n                'user_nb_mean', 'user_count',\n                'is_easy_part', 'is_medium_part', 'is_difficult_part'\n                ]\n\n\nX = train_df[features_bsl]\nX = sc.fit_transform(X)\ny = train_df['answered_correctly']\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from lightgbm import LGBMClassifier\nimport lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def learning_rate_010_decay_power_099(current_iter):\n    base_learning_rate = 0.1\n    lr = base_learning_rate  * np.power(.99, current_iter)\n    return lr if lr > 1e-3 else 1e-3\n\ndef learning_rate_010_decay_power_0995(current_iter):\n    base_learning_rate = 0.1\n    lr = base_learning_rate  * np.power(.995, current_iter)\n    return lr if lr > 1e-3 else 1e-3\n\ndef learning_rate_005_decay_power_099(current_iter):\n    base_learning_rate = 0.05\n    lr = base_learning_rate  * np.power(.99, current_iter)\n    return lr if lr > 1e-3 else 1e-3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fit_params={\"early_stopping_rounds\":30, \n            \"eval_metric\" : 'auc', \n            \"eval_set\" : [(X_test,y_test)],\n            'eval_names': ['valid'],\n            #'callbacks': [lgb.reset_parameter(learning_rate=learning_rate_010_decay_power_099)],\n            'verbose': 100,\n            'categorical_feature': 'auto'}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import randint as sp_randint\nfrom scipy.stats import uniform as sp_uniform\nparam_test ={'num_leaves': sp_randint(6, 50), \n             'min_child_samples': sp_randint(100, 500), \n             'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n             'subsample': sp_uniform(loc=0.2, scale=0.8), \n             'colsample_bytree': sp_uniform(loc=0.4, scale=0.6),\n             'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n             'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#This parameter defines the number of HP points to be tested\nn_HP_points_to_test = 100\n\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n\n#n_estimators is set to a \"large value\". The actual number of trees build will depend on early stopping and 5000 define only the absolute maximum\nclf = lgb.LGBMClassifier(max_depth=7, random_state=1, metric='None', n_jobs=4, n_estimators=200)\ngs = RandomizedSearchCV(\n    estimator=clf, param_distributions=param_test, \n    n_iter=n_HP_points_to_test,\n    scoring='roc_auc',\n    cv=3,\n    refit=True,\n    random_state=1,\n    verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#gs.fit(X_train, y_train, **fit_params)\n#print('Best score reached: {} with params: {} '.format(gs.best_score_, gs.best_params_))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Best score reached: 0.7514851143810443 with params: {'colsample_bytree': 0.9080972808940212, 'min_child_samples': 343, 'min_child_weight': 0.01, 'num_leaves': 42, 'reg_alpha': 5, 'reg_lambda': 0, 'subsample': 0.863184719640143} "},{"metadata":{"trusted":true},"cell_type":"code","source":"y.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = lgb.LGBMClassifier(max_depth=7, \n                         random_state=1, metric='None', \n                         n_jobs=4, n_estimators=200)\n\n\nparams = {\n    #'bagging_fraction': 0.5817242323514327,\n    'feature_fraction': 0.6884588361650144,\n    #'learning_rate': 0.42887924851375825, \n    'learning_rate': 0.4, \n    'max_depth': 7,\n    'min_child_samples': 100, \n    'min_child_weight': 0.01,\n    'min_data_in_leaf': 20, \n    'n_estimators': 200,\n    'n_job': 4,\n    'num_leaves': 42,\n    'random_state': 1,\n    'reg_alpha': 5, \n    'reg_lambda': 0,\n    'subsample': 0.863184719640143\n}\n\nlgbm = LGBMClassifier( **params)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[features_bsl].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm.fit(train_df[features_bsl], y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nroc_auc_score(y.values, lgbm.predict_proba(train_df[features_bsl])[:,1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#displaying the most important features\nlgb.plot_importance(lgbm)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import riiideducation\nimport pandas as pd\n\nenv = riiideducation.make_env()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import defaultdict\nuser_sum_dict = user_agg['sum'].astype('int16').to_dict(defaultdict(int))\nuser_count_dict = user_agg['count'].astype('int16').to_dict(defaultdict(int))\ncontent_sum_dict = content_agg['sum'].astype('int32').to_dict(defaultdict(int))\ncontent_count_dict = content_agg['count'].astype('int32').to_dict(defaultdict(int))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"iter_test = env.iter_test()\n\nfor (test_df, sample_prediction_df) in iter_test:\n    test_df = test_df[test_df['content_type_id'] == 0]\n    test_df['is_first_question'] = 0\n    \n    test_df.loc[test_df['prior_question_had_explanation'].isna(),'is_first_question'] = 1\n    \n    test_df['prior_question_had_explanation'].fillna(False, inplace=True)\n    test_df.loc[test_df[\"prior_question_had_explanation\"]== True, \"prior_had_explanation_le\"] = 1\n    test_df.loc[test_df[\"prior_question_had_explanation\"]== False, \"prior_had_explanation_le\"] = 0\n    \n    prior_question_elapsed_time_mean = test_df[~test_df['prior_question_elapsed_time'].isna()]['prior_question_elapsed_time'].mean()\n    test_df['prior_question_elapsed_time'].fillna(prior_question_elapsed_time_mean, inplace=True)\n    \n    \n    test_df = pd.merge(test_df,questions_df, how='left', left_on='content_id', right_on='question_id').sort_values('row_id')\n    test_df = test_df.sort_values(['user_id','timestamp'], ascending=False)\n    \n    user_sum = np.zeros(len(test_df), dtype=np.int16)\n    user_count = np.zeros(len(test_df), dtype=np.int16)\n    content_sum = np.zeros(len(test_df), dtype=np.int32)\n    content_count = np.zeros(len(test_df), dtype=np.int32)\n    for i, (user_id, content_id) in enumerate(zip(test_df['user_id'].values, test_df['content_id'].values)):\n        user_sum[i] = user_sum_dict[user_id]\n        user_count[i] = user_count_dict[user_id]\n        content_sum[i] = content_sum_dict[content_id]\n        content_count[i] = content_count_dict[content_id]\n\n    test_df['user_count'] = user_count\n    test_df['user_sum'] = user_sum\n    test_df.loc[test_df[\"user_count\"]==0, \"user_count\"] = test_df[test_df[\"user_count\"]==0][\"user_sum\"]\n    \n    test_df['user_nb_mean'] = user_sum /user_count\n    \n    test_df['part'] = test_df.part - 1\n    test_df['part'].fillna(4, inplace = True)\n    \n    # New user ? Pas encore de réponses ?\n    test_df['content_count'] = content_count\n    test_df['content_nb_mean'] = content_sum/content_count\n    \n    test_df['prior_question_elapsed_time_in_min'] = test_df['prior_question_elapsed_time']/1000/60/60\n    test_df['timestamp_by_month'] = test_df['timestamp']/nbMillisecByMonth\n    X = test_df[features_bsl]\n    #X = sc.fit_transform(X)\n    \n    test_df['answered_correctly'] =  lgbm.predict(X)\n    env.predict(test_df.loc[test_df['content_type_id'] == 0, ['row_id', 'answered_correctly']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}